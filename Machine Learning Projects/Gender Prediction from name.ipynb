{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qHloCiWHhblM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "087V5dhO8Kgu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98c559e9-4556-4557-8f7b-26f390b11b20"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'MachineLearningRecipes'...\n",
            "remote: Enumerating objects: 241, done.\u001b[K\n",
            "remote: Total 241 (delta 0), reused 0 (delta 0), pack-reused 241\u001b[K\n",
            "Receiving objects: 100% (241/241), 3.49 MiB | 14.85 MiB/s, done.\n",
            "Resolving deltas: 100% (60/60), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/MahadiHasanNahid/MachineLearningRecipes.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import sklearn.datasets\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import tree"
      ],
      "metadata": {
        "id": "JxJBsFYm-NKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_path_male = \"MachineLearningRecipes/GuessingName/train/male\"\n",
        "train_path_female =  \"MachineLearningRecipes/GuessingName/train/female\"\n",
        "\n",
        "train_path = \"MachineLearningRecipes/GuessingName/train\"\n",
        "test_path = \"MachineLearningRecipes/GuessingName/test\"\n",
        "\n",
        "categories = [\n",
        "   'male',\n",
        "   'female'\n",
        "]\n",
        "\n",
        "train_data = sklearn.datasets.load_files(train_path, \n",
        "                                         description=None, categories=None, load_content=True, shuffle=True,\n",
        "                                         encoding='utf-8', decode_error='strict', random_state=42)"
      ],
      "metadata": {
        "id": "aw6iqqmm-vp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing trained data\n",
        "train_data.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYXV3Iza-y8N",
        "outputId": "da5fcb43-8cb1-474d-ca22-b7da1db845d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sohel Rana Sagor\\nAhiya Ahmed Rejman\\nAnurudha Das Ayon\\nBhupen Chandra Sen\\nMifta Hur Rahman Fayez\\nArfa Ahmed\\nManna Ahmed\\nJubayed Ibna Sadique\\nSayed Golam Ehsani\\nShahnewaz Jalali\\nAkikur Rahman Rabbi\\nAbdul Hadi\\nAshraf - Ul - Alam Sani\\nHussain Ahmed\\nJahed Ahmad\\nRajwan Ahmed Chowdhury\\nShahanur Ahmed\\nSyed Nahmad Ahmed\\nShofi Ahmed Chowdhury\\nTanvir Ahmed Saimon\\nNahif Ahmed\\nMasum Ahmed\\nJoglu Ahmed\\nOlid Ahmed Chowdhury\\nSk. Md. Fahad Ahmed\\nAfjal Ahmed\\nAbaydur Rahman Titu\\nLayek Ahmed\\nSyed Tambir Ahmed\\nSyed Bappi Ahmed\\n',\n",
              " 'Syeda Iffat Tanjin\\nMiss Kamara Begum\\nKamelia Sultana\\nKeya Sultana Chowdhury\\nSheuly Begum\\nFahmida Suriya Tanha\\nNajia Ferdous\\nTahmina Begum Urmi\\nRumana Begum Rumi\\nFahmida Jannat Lima\\nRazia Sultana\\nRahima Khatun Shimmi\\nKulsuma Begum Dina\\nRoksana Begum\\nMukti Rani Das\\nSima Begum\\nFarhana Jahan\\nNadira Akther Lovely\\nA.K.M. Jahangir\\nSadia Begum\\nYasmin Begum\\nSoltana Akter\\nFarjana Sultana Sonia\\nNaila Sultana\\nTahmina Shikdar Ema\\nUmme Kulsum Ayesha\\nNafisha Iftekhar\\nChowdhury Silma Pasha\\nTitly Baidya Trina\\nKamrunnahar Tamanna\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "count_vect = CountVectorizer()\n",
        "x_train_counts = count_vect.fit_transform(train_data.data)\n",
        "tfidf_transformer = TfidfTransformer(use_idf=True).fit(x_train_counts)\n",
        "x_train_tfidf = tfidf_transformer.transform(x_train_counts)\n",
        "x_train = x_train_tfidf.toarray()\n",
        "y_train = train_data.target\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "\n",
        "#print(\"Tarin Data : \", train_data.data)\n",
        "\n",
        "train_data = -1\n",
        "x_train_counts = -1\n",
        "x_train_tfidf = -1\n",
        "\n",
        "# ============================= loading test data and normalizing it ======================================= #\n",
        "\n",
        "test_data = sklearn.datasets.load_files(test_path, \n",
        "                                         description=None, categories=None, load_content=True, shuffle=True,\n",
        "                                         encoding='utf-8', decode_error='strict', random_state=42)\n",
        "\n",
        "\n",
        "x_test_counts = count_vect.transform(test_data.data)\n",
        "x_test_tfidf = tfidf_transformer.transform(x_test_counts)\n",
        "x_test = x_test_tfidf.toarray()\n",
        "y_test = test_data.target\n",
        "x_test = scaler.transform(x_test)\n",
        "\n",
        "#print(\"test Data : \", test_data.data)\n",
        "\n",
        "#print(\"Test data : \", x_test)\n",
        "test_data = -1 \n",
        "x_test_counts = -1\n",
        "x_test_tfidf = -1"
      ],
      "metadata": {
        "id": "bnlgY_ZI_ONI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "menData = []\n",
        "with open('MachineLearningRecipes/GuessingName/inputMen.txt') as inputfile:\n",
        "    for line in inputfile:\n",
        "        menData.append(line.strip().split('\\n'))\n",
        "\n",
        "#print(\"data: \", menData)\n",
        "\n",
        "womenData = []\n",
        "with open('MachineLearningRecipes/GuessingName/inputWomen.txt') as inputfile:\n",
        "    for line in inputfile:\n",
        "        womenData.append(line.strip().split('\\n'))\n",
        "\n",
        "#print(\"data: \", menData)\n",
        "\n",
        "trainData = menData + womenData\n",
        "X_train = trainData\n",
        "#print(\"data: \", X_train)\n",
        "\n",
        "y_train = []\n",
        "\n",
        "for i in menData:\n",
        "    y_train.append(1)\n",
        "for i in womenData:\n",
        "    y_train.append(0)\n",
        "#print(\"label: \", y_train)    \n",
        "\n",
        "testData = [name.split('\\n') for name in ['Arfa Ahmed', 'Nahif Ahmed', 'Jubayed Ibna Sadique', 'Nahif Ahmed', 'Ali Ahmed' 'Sayed Golam Ehsani', 'Abdul Hadi', 'Jubaida Sultana', 'Syed Bappi Ahmed'] ]\n",
        "\n",
        "\n",
        "#-----------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "x_train_list = []\n",
        "\n",
        "for data in X_train: \n",
        "    #print(\"data: \", data)\n",
        "    x_test_counts = count_vect.transform(data)\n",
        "    x_test_tfidf = tfidf_transformer.transform(x_test_counts)\n",
        "    x_test = x_test_tfidf.toarray()\n",
        "    x_test = scaler.transform(x_test)\n",
        "    x_train_list.append(x_test[0])\n",
        "\n",
        "\n",
        "x_test_list = []\n",
        "\n",
        "for data in testData: \n",
        "    x_test_counts = count_vect.transform(data)\n",
        "    x_test_tfidf = tfidf_transformer.transform(x_test_counts)\n",
        "    x_test = x_test_tfidf.toarray()\n",
        "    x_test = scaler.transform(x_test)\n",
        "    x_test_list.append(x_test[0])\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "\n",
        "\n",
        "clf = clf.fit(x_train_list, y_train)\n",
        "\n",
        "prediction = clf.predict(x_test_list)\n",
        "\n"
      ],
      "metadata": {
        "id": "L47oqWnt_rMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMeq2jl9Cq7Z",
        "outputId": "fd77d701-4f76-4416-8fa1-85e1f90f6a59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    }
  ]
}